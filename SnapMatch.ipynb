{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf268050-5688-47cd-96e2-9bd9b4c55d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import dlib\n",
    "import hdbscan\n",
    "import cv2\n",
    "import os \n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58df62b6-a77a-45a6-9dec-0addcf9aedbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Vyom/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Vyom/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Vyom/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Vyom/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Vyom/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vyom\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Face Not Detected By InsightFace\n",
      "Error: Face Not Detected By InsightFace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vyom\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    }
   ],
   "source": [
    "class FaceClassifier:\n",
    "    def __init__(self, path: str):\n",
    "        self.base_dir = path\n",
    "        self.detect = MTCNN()\n",
    "        self.app = FaceAnalysis('buffalo_l')\n",
    "        self.app.prepare(ctx_id=0, det_size=(256, 256))\n",
    "        self.predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    def detect_face(self, img_path: str):\n",
    "        embedding_faces = []\n",
    "        aligned_faces = []\n",
    "        for obj in os.listdir(img_path):\n",
    "            img = cv2.imread(os.path.join(img_path, obj))\n",
    "            img, s_h, s_w = self.resize(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            faces = self.detect.detect_faces(img)\n",
    "            face_val = self.landmarks(img, faces, s_h, s_w)\n",
    "            if face_val:\n",
    "                aligned_faces.extend(face_val)\n",
    "                embedding_faces.extend(self.embedding(face_val))\n",
    "        return aligned_faces, embedding_faces\n",
    "\n",
    "    def resize(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        scale = 1024 / max(h, w)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        img = cv2.resize(img, (new_w, new_h))\n",
    "        return img, scale, scale\n",
    "\n",
    "    def landmarks(self, img, faces, s_h, s_w):\n",
    "        face_list = []\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['box']\n",
    "            orig_w, orig_h = int(w * (1 / s_w)), int(h * (1 / s_h))\n",
    "            x, y = max(0, x - 10), max(0, y - 10)\n",
    "            w, h = min(x + w + 20, img.shape[1]) - x, min(y + h + 20, img.shape[0]) - y\n",
    "            crop_img = img[y:y + h, x:x + w]\n",
    "            resized_img = cv2.resize(crop_img, (orig_w, orig_h))\n",
    "\n",
    "            shape = self.predictor(resized_img, dlib.rectangle(0, 0, resized_img.shape[1], resized_img.shape[0]))\n",
    "            landmark = face_utils.shape_to_np(shape)\n",
    "            aligned_img = self.alignment(resized_img, landmark)\n",
    "\n",
    "            if aligned_img is not None:\n",
    "                face_list.append(aligned_img)\n",
    "        return face_list\n",
    "\n",
    "    def alignment(self, img, landmark):\n",
    "        left_eye = landmark[36:42].mean(axis=0)\n",
    "        right_eye = landmark[42:48].mean(axis=0)\n",
    "        dx, dy = right_eye[0] - left_eye[0], right_eye[1] - left_eye[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        centre = ((left_eye[0] + right_eye[0]) / 2, (left_eye[1] + right_eye[1]) / 2)\n",
    "        dist = np.sqrt((dx ** 2) + (dy ** 2))\n",
    "        actual_dist = 0.3 * img.shape[1]\n",
    "        scale = actual_dist / dist\n",
    "\n",
    "        M = cv2.getRotationMatrix2D(centre, angle, scale)\n",
    "        M[0, 2] += 0.5 * img.shape[1] - centre[0]\n",
    "        M[1, 2] += 0.35 * img.shape[0] - centre[1]\n",
    "\n",
    "        img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "        return self.check_alignment(img)\n",
    "\n",
    "    def check_alignment(self, img):\n",
    "        faces = self.detect.detect_faces(img)\n",
    "        if not faces:\n",
    "            return None\n",
    "        x, y, w, h = faces[0]['box']\n",
    "        cropped_img = img[y:y + h, x:x + w]\n",
    "\n",
    "        shape = self.predictor(cropped_img, dlib.rectangle(0, 0, cropped_img.shape[1], cropped_img.shape[0]))\n",
    "        landmark = face_utils.shape_to_np(shape)\n",
    "\n",
    "        left_eye = landmark[36:42].mean(axis=0)\n",
    "        right_eye = landmark[42:48].mean(axis=0)\n",
    "        eye_alignment_error = abs(left_eye[1] - right_eye[1])\n",
    "\n",
    "        return cropped_img if eye_alignment_error < h * 0.04 else None\n",
    "\n",
    "    def embedding(self, face_list):\n",
    "        embeddings = []\n",
    "        for face in face_list:\n",
    "            faces = self.app.get(face)\n",
    "            if faces:\n",
    "                embeddings.append(faces[0].embedding)\n",
    "            else:\n",
    "                print(\"Error: Face Not Detected By InsightFace\")\n",
    "        return embeddings\n",
    "\n",
    "    def clustering(self, embedding,faces):\n",
    "        if not embedding:\n",
    "            return {}\n",
    "        scan = hdbscan.HDBSCAN(min_cluster_size=3, cluster_selection_epsilon=0.3)\n",
    "        embedding = np.array(embedding)\n",
    "        labels = scan.fit_predict(embedding)\n",
    "        clusters = defaultdict(list)\n",
    "        for i, label in enumerate(labels):\n",
    "            if label != -1:\n",
    "                clusters[label].append((embedding[i],faces[i]))\n",
    "        return clusters\n",
    "\n",
    "    def find_best_cluster(self, embedding_vector, clusters):\n",
    "        embedding_vector = np.array(embedding_vector).reshape(1, -1)\n",
    "        max_similarities = []\n",
    "\n",
    "        for cluster_id, embeddings_faces in clusters.items():\n",
    "            embeddings = np.array([e for e, _ in embeddings_faces]) \n",
    "            if embeddings.size == 0:\n",
    "                continue\n",
    "            centroid = np.mean(embeddings, axis=0).reshape(1, -1)\n",
    "            similarity = cosine_similarity(embedding_vector, centroid)[0][0]\n",
    "            max_similarities.append((cluster_id, similarity))\n",
    "\n",
    "        max_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return max_similarities[:3]\n",
    "\n",
    "    def find_best_match(self, embedding_vector, clusters):\n",
    "        top_clusters = self.find_best_cluster(embedding_vector, clusters)\n",
    "        best_similarity, best_cluster = -1, None\n",
    "\n",
    "        for cluster_id, _ in top_clusters:\n",
    "            embedding=clusters[cluster_id]\n",
    "            for embedding_face in embedding :\n",
    "                emb=embedding_face[0]\n",
    "                sim = cosine_similarity(embedding_vector.reshape(1, -1), emb.reshape(1, -1))[0][0]\n",
    "                if sim > best_similarity:\n",
    "                    best_similarity = sim\n",
    "                    best_cluster = cluster_id\n",
    "                if best_similarity > 0.8:\n",
    "                    return best_similarity, best_cluster\n",
    "\n",
    "        return best_similarity, best_cluster\n",
    "\n",
    "def main():\n",
    "    base_dir = \"D:/TensorFlow 2.0/Main Project\"\n",
    "    system = FaceClassifier(base_dir)\n",
    "    \n",
    "    train_path = os.path.join(base_dir, \"test\")\n",
    "    train_faces, train_embeddings = [], []\n",
    "    \n",
    "    for obj in os.listdir(train_path):\n",
    "        train_face, train_embedding = system.detect_face(os.path.join(train_path, obj))\n",
    "        train_faces.extend(train_face)\n",
    "        train_embeddings.extend(train_embedding)\n",
    "    \n",
    "    clusters = system.clustering(train_embeddings,train_faces)\n",
    "    test_path = os.path.join(base_dir, \"New folder\")\n",
    "    test_faces, test_embeddings = system.detect_face(test_path)\n",
    "\n",
    "    for embedding in test_embeddings:\n",
    "        similarity, cluster_id = system.find_best_match(embedding, clusters)\n",
    "        if cluster_id is not None:\n",
    "            print_img(cluster_id, clusters)\n",
    "\n",
    "def print_img(cluster_id, clusters):\n",
    "    if cluster_id not in clusters:\n",
    "        print(\"No matching cluster found\")\n",
    "        return\n",
    "    for i, (_,img) in enumerate(clusters[cluster_id]):\n",
    "        if img is None or not isinstance(img, np.ndarray):\n",
    "            print(\"Error: Invalid image format\")\n",
    "            continue\n",
    "        cv2.imshow(\"Image\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "        cv2.waitKey(0)\n",
    "        if i == 10:\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4c496d-4eca-4d67-9ecc-22061609fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f91ee16-6515-48b8-9ea1-448b271a47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"D:/TensorFlow 2.0/Main Project\"\n",
    "i=0\n",
    "train=pd.DataFrame(columns=[\"Image\",\"Label\"])\n",
    "dir_path=os.path.join(base_dir,\"train\")\n",
    "for img_path in os.listdir(dir_path):\n",
    "    img1_path=os.path.join(dir_path,img_path)\n",
    "    for img in os.listdir(img1_path):\n",
    "        train=pd.concat([train,pd.DataFrame({\"Image\":[cv2.imread(os.path.join(img1_path,img))],\"Label\":[i]})],axis=0)\n",
    "    i+=1\n",
    "train_test,test=train_test_split(train,test_size=0.2,random_state=365)\n",
    "train_test=train_test.reset_index(drop=True)\n",
    "test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bfdcb5-86e4-4b35-a9d1-de3d3397db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Image Label\n",
      "0     [[[49, 60, 92], [60, 75, 108], [80, 97, 136], ...    68\n",
      "1     [[[34, 36, 36], [31, 33, 33], [35, 37, 37], [1...    19\n",
      "2     [[[244, 254, 254], [244, 254, 254], [244, 254,...    62\n",
      "3     [[[135, 137, 137], [135, 137, 137], [136, 138,...    72\n",
      "4     [[[215, 221, 220], [215, 221, 220], [215, 221,...    52\n",
      "...                                                 ...   ...\n",
      "6769  [[[111, 98, 250], [111, 98, 250], [111, 97, 25...    53\n",
      "6770  [[[93, 72, 70], [96, 77, 74], [97, 77, 76], [9...    68\n",
      "6771  [[[129, 152, 160], [126, 149, 157], [127, 149,...    25\n",
      "6772  [[[250, 240, 240], [250, 240, 240], [250, 240,...    20\n",
      "6773  [[[114, 135, 166], [104, 125, 156], [91, 112, ...    71\n",
      "\n",
      "[6774 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81fa5264-4e80-4930-9f90-7b2c953eb31e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclusters\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clusters' is not defined"
     ]
    }
   ],
   "source": [
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a6d3e-7d36-4003-9196-ac277ee2b07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
